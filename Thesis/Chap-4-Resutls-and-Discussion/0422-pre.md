# Tuned parameters

|Machine learning techniques|Model names|
|:---             |:---                 |
|Ensemble learning|RF                   |
|Deep learning    |CNN                  |
|Deep learning    |DNN                  |
|Deep learning    |RNN                  |
|Deep learning    |GRU                  |
|Deep learning    |LSTM                 |

Table: Candidate models for NH$_{3}$N forecasting^[All the hyper-parameters are set to be the same. Hidden layer = 10, output layer = 3, learning rate = 5e-05, epoch = 100,  experiment times = 3, and scheduler is used for regularization (patience=10, factor=0.5).]. {#tbl:id}

\pagebreak

|Parameter|Values           |Pre-processing methods  |Parameters|
|:---  |:---                |:---         |:---      |
|Input |24 hours            |SG 1         |span=5    |
|Output|3 hours             |SG 2         |span=7    |
|Train |12/23/21 to 1/09/22|SG 3         |span=9    |
|Valid | 1/10/22 to 1/15/22|EWMA 1       |span=2    |
|Test  | 1/16/22 to 1/22/22|EWMA 2       |span=3    |
|      |                    |EWMA 3       |span=4    |
|      |                    |OR[^3]       |-         |

Table: Configurations for NH$_{3}$N forecasting. {#tbl:id}

[^3]:Three days were identified as outliers and removed from the training dataset.

\pagebreak

# Reuslt 1 (Exp-1)
## test and val loss comparison
* First time showing the results in decending order of test loss.
* LSTM and GRU have lower test loss than RNN, DNN, and RF.
* The lowest test loss of NH$_{3}$N forecasting approach has higher validation loss than several approaches.

|Rank|Model-Dataset|Test loss$^{*}$|valid loss |
|:---:|:---|:---|:---|
|1 |GRU-sg7  |0.0383 \pm0.0007|  1.2508 \pm0.0458|
|2 |GRU-sg5  |0.0385 \pm0.0001|  1.2644 \pm0.0081|
|3 |LSTM-ew3 |0.0388 \pm0.0006|**1.0796 \pm0.0112**(1)|
|4 |LSTM-sg7 |0.0388 \pm0.0003|  1.1804 \pm0.0296|
|5 |LSTM-sg5 |0.0388 \pm0.0003|  1.2346 \pm0.0520|
|6 |GRU-ew2  |0.0389 \pm0.0004|  1.1891 \pm0.0307|
|7 |GRU-ew4  |0.0391 \pm0.0004|  1.2390 \pm0.0557|
|8 |LSTM-ew2 |0.0392 \pm0.0006|**1.0969 \pm0.0159**(2)|
|9 |GRU-ew3  |0.0392 \pm0.0002|  1.2199 \pm0.0137|
|10|LSTM-ew4|0.0395 \pm0.0010|**1.1219 \pm0.0079**(3)|
|11|GRU-sg9 |0.0396 \pm0.0003|  1.3097 \pm0.0175|
|12|LSTM-or |0.0398 \pm0.0003|  1.2612 \pm0.0269|
|13|LSTM-obs|0.0405 \pm0.0004|  1.2366 \pm0.0150|
|14|GRU-or  |0.0405 \pm0.0002|  1.3993 \pm0.0532|
|15|LSTM-sg9|0.0410 \pm0.0005|  1.3076 \pm0.0214|
|16|GRU-obs |0.0414 \pm0.0005|  1.3638 \pm0.0359|
|17|RNN-sg5 |0.0415 \pm0.0001|  1.5088 \pm0.0336|
|18|RNN-ew2 |0.0421 \pm0.0007|  1.5425 \pm0.0566|
|19|RNN-sg7 |0.0423 \pm0.0008|  1.6267 \pm0.0065|
|20|RNN-ew4 |0.0432 \pm0.0003|  1.5992 \pm0.0300|

Table: Evaluation of each baseline approach for NH$_{3}$N forecasting. {#tbl:id}

\pagebreak

## Point out the top forecasting approach of the test loss didn't have the lowest validation loss.
* Test dataset from 1/16 to 1/22 performed differently on the same forecasting approach compared to validation loss.

|GRU|Test loss$^{*}$|Val loss |LSTM|Test loss$^{*}$|Val loss |
|:---:|:---|:--|:---:|:---|:---|
|sg7|0.0383\pm0.0007|       1.2508\pm0.0458|ew3|	  0.0388\pm0.0006|     **1.0796\pm0.0112**(1)|
|sg5|0.0385\pm0.0001|       1.2644\pm0.0081|sg7|	  0.0388\pm0.0003|       1.1804\pm0.0296|
|ew2|0.0389\pm0.0004|     **1.1891\pm0.0307**(1)|sg5|	  0.0388\pm0.0003|       1.2346\pm0.0520|
|ew4|0.0391\pm0.0004|     **1.2390\pm0.0557**(3)|ew2|    0.0392\pm0.0006|     **1.0969\pm0.0159**(2)|
|ew3|0.0392\pm0.0002|     **1.2199\pm0.0137**(2)|ew4|	  0.0395\pm0.0010|     **1.1219\pm0.0079**(3)|
|sg9|0.0396\pm0.0003|       1.3097\pm0.0175|or |      0.0398\pm0.0003|       1.2612\pm0.0269|
|or	|0.0405\pm0.0002|       1.3993\pm0.0532|obs|      0.0405\pm0.0004|       1.2366\pm0.0150|
|obs|0.0414\pm0.0005|       1.3638\pm0.0359|sg9|	  0.0410\pm0.0005|       1.3076\pm0.0214|

Table: Comparison of NH$_{3}$N val/test loss from 1/16 to 1/22. {#tbl:id}

\pagebreak



## Test dataset from 10/10 to 10/16 performed similar on the same forecasting approach compared to validation loss.

|GRU|Test loss|Val loss|LSTM|Test loss|Val loss |
|:---:|:---|:---|:---:|:---|:---|
|ew3|0.0167\pm0.0000|**1.2199\pm0.0137**(2)|ew3|0.0158\pm0.0004|**1.0796\pm0.0112**(1)|
|ew4|0.0169\pm0.0001|**1.2390\pm0.0557**(3)|ew2|0.0161\pm0.0000|**1.0969\pm0.0159**(2)|
|ew2|0.0170\pm0.0004|**1.1891\pm0.0307**(1)|ew4|0.0163\pm0.0003|**1.1219\pm0.0079**(3)|
|sg9|0.0174\pm0.0002|  1.3097\pm0.0175     |sg5|0.0166\pm0.0001|  1.2346\pm0.0520|
|sg5|0.0178\pm0.0004|  1.2644\pm0.0081     |obs|0.0175\pm0.0001|  1.2366\pm0.0150|
|sg7|0.0180\pm0.0005|  1.2508\pm0.0458     |or |0.0177\pm0.0002|  1.2612\pm0.0269|
|or |0.0187\pm0.0002|  1.3993\pm0.0532     |sg7|0.0180\pm0.0002|  1.1804\pm0.0296|
|obs|0.0189\pm0.0002|  1.3638\pm0.0359     |sg9|0.0188\pm0.0002|  1.3076\pm0.0214|

Table: Val/test loss of $\mathrm{NH_{3}N}$ from 10/10 to 10/16. {#tbl:id}


\pagebreak

## The influence of each pre-processing method on model training is different.

|Rank|GRU[^4]|$\mathrm{LSTM^{3}}$|GRU[^5]|$\mathrm{LSTM^{4}}$|
|:---:|:---:|:---:|:---:|:---:|
|1|sg7|ew3|ew3|ew3|
|2|sg5|sg7|ew4|ew2|
|3|ew2|sg5|ew2|ew4|
|4|ew4|ew2|sg9|sg5|
|5|ew3|ew4|sg5|obs|
|6|sg9|or |sg7|or |
|7|or |obs|or |sg7|
|8|obs|sg9|obs|sg9|

Table: Evaluation of pre-processing methods on LSTM and GRU. {#tbl:id}

[^4]: Test loss from 1/16 to 1/22
[^5]: Test loss from 10/10 to 10/16.

\pagebreak

# Result 2 (Exp-2)

|LSTM|Test loss|LSTM-3[^*]|Test loss||
|:---:|:---|:---:|:---:|
|ew3|0.0158\pm0.0004|ew3|0.0149\pm0.0001|
|ew2|0.0161\pm0.0000|ew2|0.0150\pm0.0003|
|ew4|0.0163\pm0.0003|ew4|0.0152\pm0.0002|
|sg5|0.0166\pm0.0001|sg7|0.0155\pm0.0003|
|obs|0.0175\pm0.0001|sg5|0.0156\pm0.0001|
|or |0.0177\pm0.0002|or |0.0156\pm0.0002|
|sg7|0.0180\pm0.0002|sg9|0.0160\pm0.0005|
|sg9|0.0188\pm0.0002|obs|0.0164\pm0.0003|

Table: Evaluation of LSTM trained with positional encoding. {#tbl:id}

[^*]: Number 3 stands for the number of features.

\pagebreak

# Result 3 (Exp-3)
## Colour in baseline performance

|Rank|Model-Dataset|Test loss$^{*}$|valid loss|
|:---:|:---:|:---|:---|
|1 |LSTM-ew4|0.0136\pm0.0003|**0.7515\pm0.0310**(3)|
|2 |LSTM-ew3|0.0138\pm0.0001|0.7547\pm0.0057|
|3 |LSTM-ew2|0.0138\pm0.0001|0.8011\pm0.0131|
|4 |GRU-ew3|0.0140\pm0.0003|0.8068\pm0.0070|
|5 |GRU-ew2|0.0142\pm0.0001|0.8330\pm0.0104|
|6 |LSTM-sg9|0.0143\pm0.0005|**0.7137\pm0.0216**(1)|
|7 |GRU-ew4|0.0143\pm0.0001|0.7694\pm0.0071|
|8 |RNN-ew3|0.0144\pm0.0002|0.8492\pm0.0371|
|9 |RNN-sg9|0.0147\pm0.0003|0.8363\pm0.0125|
|10|RNN-ew4|0.0147\pm0.0001|0.8476\pm0.0238|
|11|LSTM-obs|0.0148\pm0.0003|0.9744\pm0.0124|
|12|GRU-obs|0.0149\pm0.0003|0.9927\pm0.0076|
|13|RNN-ew2|0.0150\pm0.0002|0.9083\pm0.0202|
|14|GRU-sg9|0.0151\pm0.0001|0.7575\pm0.0253|
|15|RNN-sg7|0.0158\pm0.0001|0.8755\pm0.0249|
|16|RNN-sg5|0.0158\pm0.0001|0.8846\pm0.0180|
|17|GRU-sg7|0.0159\pm0.0005|0.7791\pm0.0152|
|18|GRU-sg5|0.0160\pm0.0004|0.8080\pm0.0210|
|19|RNN-obs|0.0160\pm0.0001|1.0623\pm0.0394|
|20|LSTM-sg7|0.0161\pm0.0003|**0.7439\pm0.0364**(2)|

Table: Evaluation of each baseline approach for colour forecasting. {#tbl:id}

\pagebreak

|LSTM|Test loss|Val loss|LSTM-3[^*]|Test loss|Val loss|
|:---:|:---|:---|:---:|:---|:---|
|ew4|0.0136\pm0.0003|**0.7515\pm0.0310**|sg9|0.0120\pm0.0007|**0.5752\pm0.0147**|
|ew3|0.0138\pm0.0001|0.7547\pm0.0057    |ew2|0.0132\pm0.0004|  0.6585\pm0.0035|
|ew2|0.0138\pm0.0001|0.8011\pm0.0131    |ew3|0.0134\pm0.0004|  0.6479\pm0.0076|
|sg9|0.0143\pm0.0005|**0.7137\pm0.0216**|ew4|0.0135\pm0.0003|  0.6534\pm0.0196|
|obs|0.0148\pm0.0003|0.9744\pm0.0124    |obs|0.0135\pm0.0001|  0.7525\pm0.0407|
|sg7|0.0161\pm0.0003|**0.7439\pm0.0364**|sg7|0.0143\pm0.0003|**0.6152\pm0.0114**|
|sg5|0.0168\pm0.0005|0.8355\pm0.0287    |sg5|0.0144\pm0.0002|**0.6285\pm0.0143**|

Table: Evaluation of LSTM trained with positional encoding. {#tbl:id}

[^*]: Number 3 stands for the number of features.

\pagebreak

# Conclusion

|Rank|NH$_{3}$N|Test loss|Colour|Test loss|
|:---:|:---:|:---|:---:|:---|
|1|**ew3**|**0.0149\pm0.0001**|sg9|0.0120\pm0.0007|
|2|**ew2**|**0.0150\pm0.0003**|**ew2**|**0.0132\pm0.0004**|
|3|**ew4**|**0.0152\pm0.0002**|**ew3**|**0.0134\pm0.0004**|
|4|sg7|0.0155\pm0.0003|**ew4**|**0.0135\pm0.0003**|
|5|sg5|0.0156\pm0.0001|obs|0.0135\pm0.0001|
|6|or |0.0156\pm0.0002|sg7|0.0143\pm0.0003|
|7|sg9|0.0160\pm0.0005|sg5|0.0144\pm0.0002|
|8|obs|0.0164\pm0.0003|   |               |

Table: Influence of pre-processing on NH$_{3}$N and colour forecasting models. {#tbl:id}
