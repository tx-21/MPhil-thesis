{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datatransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update = 2022/04/11 12:57:06\n"
     ]
    }
   ],
   "source": [
    "#kernel = python37\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from datetime import datetime\n",
    "from keras.layers import Bidirectional\n",
    "import datetime\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from numpy import array\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#********time check\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"Last update =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all, determine the length of historical data you want to train on (n_steps_in) and forecast (n_steps_out)\n",
    "# then append the sequence on a list, then append to a list, finally turn it into array (which can be further turned into dataframes)\n",
    "\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "def series_to_supervised(data, window=1, lag=1, dropnan=True):\n",
    "    #input data is required to be a dataframe\n",
    "    data = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(window-1, 0, -1): #because we want to import the t-23 on our first columns, the number need to be called reversely\n",
    "        cols.append(data.shift(i))\n",
    "        names += [('%s(t-%d)' % (col, i)) for col in data.columns]\n",
    "    \n",
    "    # Current timestep (t=0)\n",
    "    cols.append(data)\n",
    "    names += [('%s(t)' % (col)) for col in data.columns]\n",
    "    \n",
    "    \n",
    "    # Target timestep (t=lag)\n",
    "    for i in range(-1,-(lag+1),-1): #the import of t+1 ~ t+5 is in the foward direction, the shifting values should be negative\n",
    "        cols.append(data.shift(i))\n",
    "    for i in range(1,lag+1,1):\n",
    "        names += [('%s(t+%d)' % (col, i)) for col in data.columns]\n",
    "\n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Index(['NH3_N(t-23)', 'sin_hour(t-23)', 'cos_hour(t-23)', 'sin_day(t-23)',\n",
      "       'cos_day(t-23)', 'NH3_N(t-22)', 'sin_hour(t-22)', 'cos_hour(t-22)',\n",
      "       'sin_day(t-22)', 'cos_day(t-22)',\n",
      "       ...\n",
      "       'NH3_N(t+2)', 'sin_hour(t+2)', 'cos_hour(t+2)', 'sin_day(t+2)',\n",
      "       'cos_day(t+2)', 'NH3_N(t+3)', 'sin_hour(t+3)', 'cos_hour(t+3)',\n",
      "       'sin_day(t+3)', 'cos_day(t+3)'],\n",
      "      dtype='object', length=135)\n",
      "Last edit = 2022/04/11 12:57:06\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. import train and test raw 2. select the date range for training (only train data is required) 3. resample the train and test data\n",
    "\n",
    "    # choose the start and end date for training dataset\n",
    "    start_date_train = '2021-12-23 00:00'\n",
    "    end_date_train = '2022-1-15 23:59'\n",
    "\n",
    "    start_date_test = '2022-01-16 00:00'\n",
    "    end_date_test = '2022-01-22 23:59'\n",
    "\n",
    "    for i in range(1, 9) : # There are seven datasets\n",
    "        \n",
    "\n",
    "        problem = i\n",
    "        if problem ==1:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/obs/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= \"obs\"\n",
    "\n",
    "        if problem ==2:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/sg5/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'sg5'\n",
    "\n",
    "        if problem ==3:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/sg7/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'sg7'\n",
    "\n",
    "        if problem ==4:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/sg9/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'sg9'\n",
    "\n",
    "        if problem ==5:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/ew2/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'ew2'\n",
    "\n",
    "        if problem ==6:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/ew3/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'ew3'\n",
    "\n",
    "        if problem ==7:\n",
    "            traindata = pd.read_csv('../Exp-1/data/train/ew4/train_dataset.csv',index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'ew4'\n",
    "\n",
    "        if problem ==8:\n",
    "            traindata = pd.read_csv(\"../Exp-1/data/train/or/train_dataset.csv\",index_col = 0)\n",
    "            traindata.index = pd.to_datetime(traindata.index,format = '%Y-%m-%d %H:%M' )\n",
    "            traindata = traindata[start_date_train:end_date_train]\n",
    "            name= 'or'\n",
    "\n",
    "        #share the same test data\n",
    "        testdata= pd.read_csv(\"../Exp-1/data/test/test_dataset.csv\",index_col = 0)\n",
    "        testdata.index = pd.to_datetime(testdata.index,format = '%Y-%m-%d %H:%M' )\n",
    "        testdata = testdata[start_date_test:end_date_test]\n",
    "\n",
    "\n",
    "        train = traindata.iloc[:,:]\n",
    "        test = testdata.iloc[:,:]\n",
    "\n",
    "        # choose a number of time steps\n",
    "        n_steps_in, n_steps_out = 24, 3 #only use t-4 ~ t for training, and predict t+1 ~ t+10\n",
    "\n",
    "        # split into samples\n",
    "        #train_X, train_Y = split_sequence(train, n_steps_in, n_steps_out)\n",
    "        train = series_to_supervised(train, n_steps_in, n_steps_out) #the output tyep is dataframe \n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        #print(train)\n",
    "        # train = np.concatenate((train_X, train_Y), axis=1)\n",
    "        # train = pd.DataFrame(train, columns = ['Input1', 'Input2','Input3','Input4','Input5','Output1','Output2','Output3','Output4','Output5',...'Output10])\n",
    "        # print(train.head())\n",
    "\n",
    "        # summarize the data\n",
    "        #for i in range(len(train_X)):\n",
    "        #    print(train_X[i], train_Y[i])\n",
    "\n",
    "        # split into samples\n",
    "        #test_X, test_Y= split_sequence(test, n_steps_in, n_steps_out)\n",
    "        test = series_to_supervised(test, n_steps_in, n_steps_out) #the output tyep is dataframe \n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #test = np.concatenate((test_X, test_Y), axis=1)\n",
    "        #test = pd.DataFrame(test, columns = ['Input1', 'Input2','Input3','Input4','Input5','Output1','Output2','Output3','Output4','Output5','Output6','Output7','Output8','Output9','Output10'])\n",
    "        # print(test.head())\n",
    "\n",
    "\n",
    "        if problem ==1:\n",
    "            train.to_csv('data/train/obs/train.csv')\n",
    "        if problem ==2:\n",
    "            train.to_csv('data/train/sg5/train.csv')\n",
    "        if problem ==3:\n",
    "            train.to_csv('data/train/sg7/train.csv')\n",
    "        if problem ==4:\n",
    "            train.to_csv('data/train/sg9/train.csv')\n",
    "        if problem ==5:\n",
    "            train.to_csv('data/train/ew2/train.csv')\n",
    "        if problem ==6:\n",
    "            train.to_csv('data/train/ew3/train.csv')\n",
    "        if problem ==7:\n",
    "            train.to_csv('data/train/ew4/train.csv')\n",
    "        if problem ==8:\n",
    "            train.to_csv('data/train/or/train.csv')\n",
    "\n",
    "        test.to_csv('data/test/test.csv')\n",
    "        print(train.columns)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\": main()\n",
    "\n",
    "finish = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"Last edit =\", finish)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "995efa93ae3765c2302cfbf3fe27e0eb0766ff14c0e61346faf18c86c7d5327d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
